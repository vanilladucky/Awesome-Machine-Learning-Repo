{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to a guide on Gradient Boosting ⚡️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting is one of the most powerful options out there for a machine learning algorithm and its powers really shows when utilizing tabular data.\n",
    "### It does not fear of any non-linearity in the data or any categorial variables as it is able to deal with it just fine.\n",
    "### These days, there are readily available models such as XGBoost and LightGBM which you can just call on with a few simple lines of code. \n",
    "### However, in the long run, it definitely pays to thoroughly understand the foundation of this algorithm before you blindly use it. \n",
    "### In this guide, I will walk you through the concept of Gradient Boosting, the mathematics behind it and make sure you fully grasp its concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's dive in, shall we? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://images.unsplash.com/photo-1682687982049-b3d433368cd1?q=80&w=2671&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\" style=\"width:50%;height:50%;margin:auto;\"> </div>\n",
    "<h5><center>Image from <a href=\"https://unsplash.com/s/photos/dive-in\">unsplash</a></center></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting is a pretty interesting algorithm in the sense that the technique, Gradient Descent, used widely in Deep Learning, is also applied to this very algorithm.\n",
    "#### The whole concept of Gradient Boosting is about using multiple weak models and combining them to create one powerful model that works to build on the mistake of its other previous models.\n",
    "#### Once you understand the mathematical concept behind this, trust me, you will get to see the true beauty of the simplicity behind this model's approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://miro.medium.com/v2/resize:fit:1400/1*dIHrPFBT2fmXuTXMb-3_Xw.png\" style=\"width:50%;height:50%;margin:auto;\"> </div>\n",
    "<h5><center>Image from TDS</center></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the whole Gradient Boosting Algorithm! If you can understand this in one go, I would say you are a math genius.\n",
    "#### But for the rest of us more 'normal' people, let me break this down for you. \n",
    "#### Fret not, because once all these lines are explained, you'll see why everyone is talking about Gradient Boosting and its powers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initialize the model with a constant value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE F_0(x) =  argmin_\\gamma \\sum_{i=1}^{n}L(y_i, \\gamma) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first initializing step is to find an initial constant value prediction $ F_0(x) $\n",
    "#### Of course, this is just our initial prediction so it will look like a disastrous prediction, but let's be patient and see where it goes.\n",
    "#### Forget about the left hand side for now, and let's look at the right hand side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The right hand side talks about a $\\gamma$ value that will minimize $\\sum_{i=1}^{n}L(y_i, \\gamma)$.\n",
    "#### To do this, let's take squared loss as our loss function and apply some differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE \\frac{\\partial}{\\partial\\gamma} \\sum_{i=1}^{n}L(y_i, \\gamma)  =  \\frac{\\partial}{\\partial\\gamma} \\sum_{i=1}^{n}(y_i-\\gamma)^2$$\n",
    "$$\\LARGE = -2 \\sum_{i=1}^{n} (y_i-\\gamma) $$\n",
    "$$\\LARGE = -2 \\sum_{i=1}^{n}y_i + 2n\\gamma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we are finding $\\gamma$ that minimizes $\\sum_{i=1}^{n}L(y_i, \\gamma)$, we have to make $\\frac{\\partial}{\\partial\\gamma} \\sum_{i=1}^{n}L(y_i, \\gamma)=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE -2 \\sum_{i=1}^{n}y_i + 2n\\gamma = 0$$\n",
    "$$\\LARGE n\\gamma = \\sum_{i=1}^{n}y_i$$\n",
    "$$\\LARGE \\gamma = \\frac{1}{n} \\sum_{i=1}^{n}y_i = \\overline{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All this while, we were looking for the $\\gamma$ and here we found it!\n",
    "#### In the end, it was just a simple average of the y values.\n",
    "$$\\LARGE F_0(x) = \\overline{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Looping for M times\n",
    "#### After initializing our prediction, we will loop through M times where M denotes the number of trees we will be creating for this Gradient Boosting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Computing residuals\n",
    "#### Now this might sound strange.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><i>\"What's a residual suddenly...?\"</i></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I recommend you to ignore the term 'residual' for now but instead focus on the right hand side of the equation. \n",
    "#### The right hand side is basically partially differentiating the loss between the y value and the previous prediction with respect to the previous prediction.\n",
    "#### For those of you who feel like this is a familiar equation, with the negative sign at the front, you probably have seen something similar for gradient descent in a neural network of sorts. \n",
    "#### This step is providing us the direction and magnitude in which we can take to minimize the loss function, for each sample $i$.\n",
    "#### Let's solve the right hand side of the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE -[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]_{F(x) = F_{m-1} (x)} $$\n",
    "$$\\LARGE = -\\frac{\\partial (y_i - F_{m-1}(x_i))^2}{\\partial F_{m-1}(x_i)} $$\n",
    "$$\\LARGE = 2(y_i - F_{m-1}(x_i)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the constant in this equation, 2, will give us $ y_i-F_{m-1}(x_i) $ which is the residual, thus giving it its name. \n",
    "#### This cool simplification successfully shows us that the negative gradient to follow to minimize the loss is just the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are going to train a regression tree using $x$ as features to predict for $r$, the residual.\n",
    "#### Each tree can have multiple leaves, also known as terminal nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Computing for $\\gamma_{jm}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now have to search for $\\gamma_{jm}$ where $j$ represents different terminal nodes in a tree. \n",
    "#### We will be finding the $\\gamma$ that will minimize the loss on all the samples that belong to that terminal node.\n",
    "#### Here, we are basically trying to minimize the loss/residual/difference between y and our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE \\gamma_{jm} = \\underset{\\gamma}{\\operatorname{argmin}} \\sum_{x_i \\in R_{jm}} L(y_i, F_{m-1}(x_i) + \\gamma)$$\n",
    "$$\\LARGE = \\underset{\\gamma}{\\operatorname{argmin}} \\sum_{x_i \\in R_{jm}} (y_i-F_{m-1}(x_i) - \\gamma)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE \\frac{\\partial}{\\partial \\gamma} \\sum_{x_i \\in R_{jm}} (y_i - F_{m-1}(x_i) - \\gamma)^2 = 0$$\n",
    "$$\\LARGE -2 \\sum_{x_i \\in R_{jm}} (y_i-F_{m-1}(x_i) - \\gamma) = 0$$\n",
    "$$\\LARGE n_j\\gamma = \\sum_{x_i \\in R_{jm}} (y_i-F_{m-1}(x_i))$$\n",
    "$$\\LARGE \\gamma = \\frac{1}{n_j} \\sum_{x_i \\in R_{jm}} r_{im}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The $n_j$ stands for the number of samples in that specific j terminal node\n",
    "#### Now this finding means that our optimal $\\gamma_{jm}$ is the average of our residuals in the specific terminal nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Updating our model\n",
    "#### Now that we calculated thus here, we need to update our model.\n",
    "#### We are now predicting for $F_m(x)$, the new prediction.\n",
    "#### How this is done is building on our previous tree's prediction and improving on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE F_m(x) = F_{m-1}(x) + v \\sum_{j=1}^{J_m} \\gamma_{jm} 1(x\\in R_{jm})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now this is something similar to updating the weights of a neural network.\n",
    "#### $ \\gamma_{jm} 1(x\\in R_{jm}) $ means that we pick the value of $\\gamma_{jm}$ if a given x belongs to that specific $j$ terminal node. \n",
    "#### This corresponding $\\gamma_{jm}$ is added to the previous prediction, $F_{m-1}(x)$ and produces the updated prediction, $F_m(x)$.\n",
    "#### The $v$ is a learning rate, set to control the influence the new tree has on the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it! This is the mathematical explanation of the Gradient Boosting algorithm.\n",
    "#### I would say the most important part to wrap your head around is the $\\gamma_{jm}$ which is simply the average of the residuals for the points falling into that specific terminal node.\n",
    "#### The rest of the calculation and mathematical concepts are similar to that of deep learning which is seen widely in today's scene.\n",
    "#### As for the loss function, the only limitation is that it should be differentiable. Any other loss function is acceptable too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alright! Enough of that tedious math (which is totally fun once you fall into the trap).\n",
    "#### Let's see the whole algorithm in action in code. \n",
    "#### I will outline in the code which steps the individual lines of code are referring to in the algorithm writing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "class GradientBoosting:\n",
    "\n",
    "    def __init__(self, v, n_estimators, max_depth=1):\n",
    "        self.v = v\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = [] # A list to store all the trees that are trained \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.F0 = y.mean() # Step 1\n",
    "        Fm = self.F0\n",
    "\n",
    "        for _ in range(self.n_estimators): # Step 2\n",
    "            r = y-Fm # Step 2.1 \n",
    "            tree = DecisionTreeRegressor(max_depth = self.max_depth, random_state = 42)\n",
    "            tree.fit(X,r) # Step 2.2 \n",
    "            gamma = tree.predict(X) # Step 2.3 \n",
    "            Fm += self.v * gamma # Step 2.4 \n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        Fm = self.F0\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            Fm += self.v * self.trees[i].predict(X)\n",
    "        \n",
    "        return Fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's generate some non-linear data to try out our Gradient Boosting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate non-linear data\n",
    "np.random.seed(0)\n",
    "X = np.linspace(-10, 10, 100)\n",
    "Y = 0.5 * X**2 + 3 * np.sin(X) + np.random.normal(0, 2, 100)  # Non-linear relationship with some noise\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(X, Y, color='b')\n",
    "plt.title('Non-linear Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our algorithm's RMSE is 87.81\n",
      "Sklearn's GBM's RMSE is 87.81\n"
     ]
    }
   ],
   "source": [
    "# Testing our algorithm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm = GradientBoosting(n_estimators=20, v = 0.1, max_depth=1)\n",
    "gbm.fit(X.reshape(-1,1),Y)\n",
    "rmse = mean_squared_error(Y, gbm.predict(X.reshape(-1,1)))\n",
    "print(f\"Our algorithm's RMSE is {rmse:.2f}\")\n",
    "\n",
    "sklearn_gbm = GradientBoostingRegressor(\n",
    "    n_estimators=20, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=1\n",
    ")\n",
    "sklearn_gbm.fit(X.reshape(-1,1),Y)\n",
    "sklearn_gbm_rmse = mean_squared_error(Y, sklearn_gbm.predict(X.reshape(-1,1)))\n",
    "print(f\"Sklearn's GBM's RMSE is {sklearn_gbm_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that under the hood, scikit learn's Gradient Boosting Regressor is nothing too fancy, but just religiously sticking by the mathematical writings of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ending this guide on this note would be sufficient enough for those seeking to understand what the foundation of a Gradient Boosting algorithm is. \n",
    "#### However, I believe everyone wishes to understand the popular algorithm used nowadays when it comes to boosting models, the XGBoost algorithm.\n",
    "#### Before we end, I will dive briefly into what XGBoost is about and hopefully give you a deeper understanding of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So there are some notable distinctions of XGBoost compared to a conventional gradient boosting algorithm. \n",
    "#### Some of them are: \n",
    "##### - Regularization\n",
    "##### - Tree pruning \n",
    "##### - Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So for XGBoost algorithms, we split down and make trees based on the Similarity Score as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\LARGE \\frac{(\\sum residuals)^2}{len(residuals) + \\lambda}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The $\\lambda$ here represents regularization.\n",
    "#### $\\lambda$ also controls how much to change the previous prediction by, providing users with a way to control the variance of the prediction.\n",
    "#### Now, trees are constructed to maximize this similarity score gain, either down to the maximum depth or till there is only one residual remaining in the node.\n",
    "#### Pruning comes into play when the tree is pruned from bottom up, till the point where the Gain of a parent node is greater than the hyper parameter $\\gamma$\n",
    "#### With tree pruning, XGBoost showcases improved model generalization, lowering possibility of overfitting.\n",
    "#### Parallelization is also achieved by parallel tree construction when finding for the best split at each node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I hope this guide helped you understand the Gradient Boosting algorithm. \n",
    "#### I highly suggest you to understand this algorithm and make sure you understand how it works before using it. \n",
    "#### This is a potent algorithm that is used widely in competitions for high scores due to its outperformance and robustness. \n",
    "#### With this, I will see you in the next guide!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502\n",
    "* https://medium.com/@prathameshsonawane/xgboost-how-does-this-work-e1cae7c5b6cb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('machine_deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a01aa30e7cb9fc7776677534e11c9ab1eed0bfffb3501a39ef7b976f9557b493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
